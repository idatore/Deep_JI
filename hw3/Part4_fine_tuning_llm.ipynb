{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa38025-1a01-4353-abaf-5a69c0c47c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import unittest\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import urllib\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11cce924-9bd4-45f2-a0df-73394bacabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "from datasets import DatasetDict\n",
    "from datasets import load_dataset, load_metric, concatenate_datasets\n",
    "\n",
    "from hw3 import training\n",
    "\n",
    "\n",
    "from cs236781.plot import plot_fit\n",
    "from cs236781.train_results import FitResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626375cb-dd6d-4b0e-9d42-8c8bb234e9e1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "$$\n",
    "# Part 4: Fine-Tuning a pretrained language model\n",
    "<a id=part3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08167a-6cac-4d03-806a-e60974e81f75",
   "metadata": {},
   "source": [
    "In this part , we will deal with the fine-tuning of BERT for sentiment analysis on the IMDB movie reivews dataset from the previous section.   \n",
    "BERT is a large language model developed by Google researchers in 2019 that offers a good balance between popularity and model size, which can be fine-tuned using a simple GPU.  \n",
    "\n",
    "If you aren't yet familiar, you can check it out here:  \n",
    "https://arxiv.org/pdf/1810.04805.pdf.\n",
    "(Read Section 3 for details on the model architecture and fine-tuning on downstream tasks).\n",
    "\n",
    "In particular, we will use the distilled (smaller) version of BERT, called Distil-BERT.\n",
    "Distil-BERT is widely used in production since it has 40% fewer parameters than BERT, while running 60% faster and retaining 95% of the performance in many benchmarks.\n",
    "It is recommended to glance through the Distil-BERT paper to get a feel for the model architecture and how it differs from BERT: \n",
    "https://arxiv.org/pdf/1910.01108.pdf\n",
    "\n",
    "We will download a pre-trained `Distil-BERT` from `Hugging Face`, so there is no need to train it from scratch. \n",
    "\n",
    "One of the key strengths of Hugging Face is its extensive collection of pre-trained models. These models are trained on large-scale datasets and exhibit impressive performance on various NLP tasks, such as text classification, named entity recognition, sentiment analysis, machine translation, and question answering, among others. The pre-trained models provided by Hugging Face can be easily fine-tuned for specific downstream tasks, saving significant time and computational resources.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61922e-8ee9-40bd-8abc-7b98d5515f0b",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326fe1ca-c764-4186-bfee-7a80e8caa0a8",
   "metadata": {},
   "source": [
    "We will now load and prepare the IMDB dataset as we did in the previous part.  \n",
    "Here we will load the full training and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81cd1ad-5ab0-418a-a339-4e7f7b95666f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('imdb', split=['train', 'test[12260:12740]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "146165ca-7636-46fe-bd16-1e964d6c41b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 25000\n",
      "}), Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 480\n",
      "})]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3dead5a-4b2e-400f-8551-c7fd44179627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap it in a DatasetDict to enable methods such as map and format\n",
    "dataset = DatasetDict({'train': dataset[0], 'test': dataset[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f07b25d3-0912-4586-b60b-6dc66e6746bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6ef0b-70e3-4ec5-83fb-b8b779237ef6",
   "metadata": {},
   "source": [
    "We can now access the datasets in the Dict as we would a dictionary.\n",
    "Let's print a few training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dccf69f-4f53-4f96-a882-c6ca6a5e0b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SAMPLE 0:\n",
      "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
      "Label 0: 0\n",
      "\n",
      "\n",
      "TRAINING SAMPLE 1:\n",
      "\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n",
      "Label 1: 0\n",
      "\n",
      "\n",
      "TRAINING SAMPLE 2:\n",
      "If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\n",
      "Label 2: 0\n",
      "\n",
      "\n",
      "TRAINING SAMPLE 3:\n",
      "This film was probably inspired by Godard's Masculin, féminin and I urge you to see that film instead.<br /><br />The film has two strong elements and those are, (1) the realistic acting (2) the impressive, undeservedly good, photo. Apart from that, what strikes me most is the endless stream of silliness. Lena Nyman has to be most annoying actress in the world. She acts so stupid and with all the nudity in this film,...it's unattractive. Comparing to Godard's film, intellectuality has been replaced with stupidity. Without going too far on this subject, I would say that follows from the difference in ideals between the French and the Swedish society.<br /><br />A movie of its time, and place. 2/10.\n",
      "Label 3: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(f'TRAINING SAMPLE {i}:') \n",
    "    print(dataset['train'][i]['text'])\n",
    "    label = dataset['train'][i]['label']\n",
    "    print(f'Label {i}: {label}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea96efc-beee-4bd0-9810-ae4d3a4f2da8",
   "metadata": {},
   "source": [
    "We should also check the label distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eb8333b-9271-41b8-845f-3f1694d93145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative samples in train dataset: 12500\n",
      "positive samples in train dataset: 12500\n",
      "negative samples in test dataset: 240\n",
      "positive samples in test dataset: 240\n"
     ]
    }
   ],
   "source": [
    "def label_cnt(type):\n",
    "    ds = dataset[type]\n",
    "    size = len(ds)\n",
    "    cnt= 0 \n",
    "    for smp in ds:\n",
    "        cnt += smp['label']\n",
    "    print(f'negative samples in {type} dataset: {size - cnt}')\n",
    "    print(f'positive samples in {type} dataset: {cnt}')\n",
    "    \n",
    "label_cnt('train')\n",
    "label_cnt('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb5437-c7ca-45ff-ba09-43cc8a8bb916",
   "metadata": {},
   "source": [
    "### __Import the tokenizer for the dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e913e8-9dbc-4f3a-8315-920e016082d1",
   "metadata": {},
   "source": [
    "\n",
    "We will now tokenize the text the same way we did in the previous part.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1f2f64-07ad-4260-a790-55a0c6f636b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer input max length: 512\n",
      "Tokenizer vocabulary size: 30522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idan.menashe/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "print(\"Tokenizer input max length:\", tokenizer.model_max_length)\n",
    "print(\"Tokenizer vocabulary size:\", tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc753304-4f5a-4ec5-ac2c-04a02f85c68e",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5601c7eaf81440ea9682da86ec60cde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_text(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    dataset_tokenized = dataset.map(tokenize_text, batched=True, batch_size =None)\n",
    "    return dataset_tokenized\n",
    "\n",
    "dataset_tokenized = tokenize_dataset(dataset)\n",
    "# we would like to work with pytorch so we can manually fine-tune\n",
    "dataset_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "# no need to parrarelize in this assignment\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f20fb7-d8f7-41a7-8464-33b5ab488eea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setting up the dataloaders and dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345bb695-5ebc-4927-983e-9880fedf3627",
   "metadata": {},
   "source": [
    "We will now set up the dataloaders for efficient batching and loading of the data.  \n",
    "By now, you are familiar with the Class methods that are needed to create a working Dataloader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a6770a-d5d1-4fb0-a7e7-bb15e0cba57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.ds = dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.ds[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e7119d-62fb-4e80-915d-79d25edde074",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IMDBDataset(dataset_tokenized['train'])\n",
    "test_dataset = IMDBDataset(dataset_tokenized['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b332f651-1a7c-45d4-949f-a09ad2c635db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "n_workers= 0\n",
    "\n",
    "dl_train,dl_test = [ \n",
    "    DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=12,\n",
    "    shuffle=True, \n",
    "    num_workers=n_workers\n",
    "),\n",
    "DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=12,\n",
    "    shuffle=False,\n",
    "    num_workers=n_workers\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6401fe-0590-4dec-8679-b9d0e36123d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f38db34d2e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f020ce-572c-4e8f-869e-5b92f36b6313",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Importing the model from Hugging Face\n",
    "We will now  delve into the process of loading the DistilBERT model from `Hugging Face`. DistilBERT is a distilled version of the BERT model, offering a lighter and faster alternative while retaining considerable performance on various NLP tasks.  \n",
    "Please refer to the introduction to check out the relevant papers.  \n",
    "For more info on how to use this model, feel free to check it out on the site:  \n",
    "https://huggingface.co/distilbert-base-uncased \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee7eef-3ce5-4026-8731-316dc4f2c53b",
   "metadata": {},
   "source": [
    "To begin, we will import the necessary library required for our implementation.\n",
    "It is fine if you receive a warning from `Hugging Face` to train the model on a downstream task, which is exactly what we will do on our IMDB dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1a936c1-b62f-4be3-a7e0-dc4a25af1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9135d51-fe93-48b3-bbd1-327d475b983c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09937752191b4f6cb2ee0ee2705db7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6993c8-c9d0-4aa5-a1bf-a7ff4555cc9b",
   "metadata": {},
   "source": [
    "__Let's print the model architecture to see what we are dealing with:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30274a2c-d2ac-407f-8aa2-ba2cd531d044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1c63e3-0e26-4af9-91db-5bec4bb7153e",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "We will now move on to the process of fine-tuning the model that we previously loaded from `Hugging Face`. Fine-tuning allows us to adapt the pre-trained model to our specific NLP task by further training it on task-specific data. This process enhances the model's performance and enables it to make more accurate predictions on our target task.  \n",
    "\n",
    "There are generally two approaches to fine-tuning the loaded model, each with its own advantages and considerations:  \n",
    "\n",
    "1) __Freeze all the weights besides the last two linear layers and train only those layers__:  \n",
    "This approach is commonly referred to as \"transfer learning\" or \"feature extraction.\" By freezing the weights of the majority of the model's layers, we retain the pre-trained knowledge captured by the model, allowing it to extract useful features from our data. We then replace and train the final few layers, typically linear layers, to adapt the model to our specific task. This method is beneficial when we have limited labeled data or when the pre-trained model has been trained on a similar domain.\n",
    "\n",
    "2) __Retrain all the parameters in the model__:  \n",
    "This approach involves unfreezing and training all the parameters of the loaded model, including the pre-trained layers. By retraining all the parameters, we allow the model to adjust its representations and update its knowledge based on our specific task and data. This method is often preferred when we have sufficient labeled data available and want the model to learn task-specific features from scratch or when the pre-trained model's knowledge may not be directly applicable to our domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ccd1bb-7e4f-4aa0-897f-1f8d73639543",
   "metadata": {},
   "source": [
    "### Fine-tuning method 1 \n",
    "__Freeze all the weights besides the last two linear layers and train only those layers__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "876d7a82-2233-4017-8221-26a46f9816a9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Freeze all parameters except for the last 2 linear layers\n",
    "# ====== YOUR CODE: ======\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad = True\n",
    "# ========================\n",
    "\n",
    "# HINT: use the printed model architecture to get the layer names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c125d-d1e9-480c-b527-ffd8e94a19ed",
   "metadata": {},
   "source": [
    "### Training \n",
    "We can use our abstract __Trainer__ class to fine-tune the model:\n",
    "We will not play around with hyperparameters in this section, as the point is to learn to fine-tune a model.   \n",
    "In addition, we do not need to send our own loss function for this loaded model (try to understand why).   \n",
    "\n",
    "__TODO__: Implement the `FineTuningTrainer` in `hw3/training.py`\n",
    "\n",
    "We will train the model for 2 epochs of 40 batches.  \n",
    "You can run this either locally or on the course servers, whichever is most comfortable for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0ed2f33-018c-4a1b-b5cc-2f9c62de89c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EPOCH 1/2 ---\n",
      "train_batch (Avg. Loss 0.698, Accuracy 48.3): 100%|██████████| 40/40 [09:08<00:00, 13.72s/it]\n",
      "test_batch (Avg. Loss 0.691, Accuracy 50.4): 100%|██████████| 40/40 [07:34<00:00, 11.37s/it]\n",
      "*** Saved checkpoint finetuned_last_2.pt at epoch 1\n",
      "--- EPOCH 2/2 ---\n",
      "train_batch (Avg. Loss 0.692, Accuracy 51.9): 100%|██████████| 40/40 [09:06<00:00, 13.67s/it]\n",
      "test_batch (Avg. Loss 0.690, Accuracy 52.3): 100%|██████████| 40/40 [07:34<00:00, 11.36s/it]\n",
      "*** Saved checkpoint finetuned_last_2.pt at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3765643/474009640.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_state = torch.load('finetuned_last_2.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best acc: 52.291666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idan.menashe/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "from hw3 import training\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-5)\n",
    "\n",
    "# fit your model\n",
    "if not os.path.exists('finetuned_last_2.pt'):\n",
    "    trainer = training.FineTuningTrainer(model, loss_fn = None, optimizer = optimizer)\n",
    "    fit_result = trainer.fit(dl_train,dl_test, checkpoints='finetuned_last_2', num_epochs=2, max_batches= 40)\n",
    "    with open('fit_result_finetune_2.pkl', 'wb') as f:\n",
    "        pickle.dump(fit_result, f)\n",
    "    \n",
    "\n",
    "saved_state = torch.load('finetuned_last_2.pt')\n",
    "model.load_state_dict(saved_state['model_state']) \n",
    "best_acc = saved_state['best_acc']\n",
    "print('best acc:', best_acc)\n",
    "\n",
    "with open('fit_result_finetune_2.pkl', 'rb') as f:\n",
    "    fit_result = pickle.load(f) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c6147f6-87e8-4615-af5d-310e3f3cf824",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_result\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Deep_JI/hw3/cs236781/plot.py:118\u001b[0m, in \u001b[0;36mplot_fit\u001b[0;34m(fit_res, fig, log_loss, legend)\u001b[0m\n\u001b[1;32m    116\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraintest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlossacc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fit_res, attr)\n\u001b[0;32m--> 118\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(attr)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lossacc \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    493\u001b[0m     x \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 494\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m index_of(xy[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1358\u001b[0m, in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;66;03m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;66;03m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;66;03m# Note this will strip unit information.\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m         \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m-> 1358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/numpy/core/shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[0;32m---> 65\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     67\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.8/site-packages/torch/_tensor.py:1083\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fit(fit_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a1dc9-4f61-43b2-bfd7-0b90a6c8edf1",
   "metadata": {},
   "source": [
    "### Fine-tuning method 2 \n",
    "__Retraining all the parameters in the model__\n",
    "\n",
    "We will reload the model to ensure that the parameters are untouched and we are starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195a86c-0ed8-4b23-8c1d-3d464c0e8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7042f-5a6f-4a92-9cd7-7ec368e76508",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b27c9c-bba4-4533-94c7-1ce9bb6ddcc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95115bc4-7c7a-456c-bcbb-1017556b12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make sure all the model parameters are unfrozen\n",
    "# ====== YOUR CODE: ======\n",
    "    \n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4bcdb-07ec-4ad1-8eeb-ed9278498cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-5)\n",
    "\n",
    "# fit your model\n",
    "if not os.path.exists('finetuned_all.pt'):\n",
    "    trainer = training.FineTuningTrainer(model, loss_fn = None, optimizer = optimizer)\n",
    "    fit_result = trainer.fit(dl_train,dl_test, checkpoints='finetuned_all', num_epochs=2, max_batches= 40)\n",
    "    with open('finetuned_all.pkl', 'wb') as f:\n",
    "        pickle.dump(fit_result, f)\n",
    "    \n",
    "\n",
    "saved_state = torch.load('finetuned_all.pt')\n",
    "model.load_state_dict(saved_state['model_state']) \n",
    "\n",
    "with open('finetuned_all.pkl', 'rb') as f:\n",
    "    fit_result = pickle.load(f)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1891724-abac-4b07-907e-6d4eddf28f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fit(fit_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45272fa-7485-442f-9b55-02e915f5996e",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ba155-e730-40ac-b3d4-b70acce56129",
   "metadata": {},
   "source": [
    "Fill out your answers in `hw3.answers.part4_q1` and `hw3.answers.part4_q2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013bc948-eaaa-42b7-a9cf-e5f5907b48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs236781.answers import display_answer\n",
    "import hw3.answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7175a5b9-f10c-40f8-ab04-a4b98cff300b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151329aa-8c63-4160-ba05-26b04f16671f",
   "metadata": {},
   "source": [
    "Explain the results that you got here in comparison to the results achieved in the *trained from scratch* encoder from the preivous part.  \n",
    "If one of the models performed better, why was this so?   \n",
    "Will this always be the case on any downstream task, or was this phenomenom specific to this task?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2133cc62-19d4-4928-b7b6-a30bfd891b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_answer(hw3.answers.part4_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8193f04-6678-4837-b10f-517ca09436d9",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f05c554-35ca-4229-8ec1-ca2a901c6f9a",
   "metadata": {},
   "source": [
    "Assume that when fine-tuning, instead of freezing the internal model layers and leaving the last 2 layers unfrozen, we instead froze the last layers and fine-tuned internal layers such as the multi-headed attention block .\n",
    "Would the model still be able to succesfully fine-tune to this task?   \n",
    "Or would the results be worse?  \n",
    "Explain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20da29-d63b-4c1c-a941-b44c5e22f92e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_answer(hw3.answers.part4_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03b78f",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101fe16d",
   "metadata": {},
   "source": [
    "If you want to conduct a machine translation task, as seen in the tutorials, can you use BERT?\n",
    "\n",
    "Describe the modulation you need to do, i.e. if the source tokens are $x_t$ and the target are $y_t$, how would the model work to produce the translation?\n",
    "\n",
    "If the model can't handle this task, describe the architecture changes and why you need them. If a change in the pre-training is required, describe it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_answer(hw3.answers.part4_q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da798bb4",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "We saw in the course two types on sequntial modeling: RNN and Transformers.\n",
    "\n",
    "What could be the main reason to choose RNN over a Transformer? Note that both can be light weight or heavy in computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea5b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_answer(hw3.answers.part4_q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6138a5b5",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "We have learned that BERT uses \"Next Sentence Prediction\" (NSP) as part of the pre-training tasks.\n",
    "\n",
    "Describe what it is (where is the prediction accure, what is the loss).\n",
    "\n",
    "Do you think this is a crucial part of pre-training? try to analize why you gave the answer, i.e. what essensity it gives to the model, or why it's implicitly don't contibute much. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_answer(hw3.answers.part4_q5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee782f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
